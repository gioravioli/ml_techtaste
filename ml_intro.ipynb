{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning with scikit-learn\n",
    "\n",
    "We go through an example of building a Logistic Regression model of the Iris dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Module Imports\n",
    "\n",
    "### Pandas\n",
    "\n",
    "We use `pandas` for data manipulation. Standard practice is to nickname as `pd`\n",
    "\n",
    "### Matplotlib\n",
    "\n",
    "We use `matplotlib` for data visualization. Standard practice is to nackname as `plt`.\n",
    "\n",
    "### Scikit-learn\n",
    "\n",
    "We use `scikit-learn` for machine learning. We are using 3 functions/classes from scikit-learn.\n",
    "\n",
    "1. `load_iris`: Function for loading the dataset we'll be using\n",
    "2. `train_test_split`: Function for splitting the data into a training set and test set\n",
    "3. `LogisticRegression`: Class for the Logistic Regression classification model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.datasets import load_iris"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Loading the data\n",
    "\n",
    "We are working with the Iris dataset, which has measurements of different Iris flowers. There are three different types of Irises.\n",
    "\n",
    "The `DESRC` attribute gives information about the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = load_iris()\n",
    "print(iris.DESCR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Pandas DataFrame\n",
    "\n",
    "We create a Pandas DataFrame with our data. This is a datatype that is used for storing a table of data.\n",
    "\n",
    "We segment the data to only use classes 1 and 2 to make the classification problem easier.\n",
    "\n",
    "The `head` method returns the first 5 rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_df = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
    "iris_df['target'] = iris.target\n",
    "iris_df = iris_df[iris_df['target'] >= 1] # use only 2 classes\n",
    "iris_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Graph the Data\n",
    "\n",
    "We use matplotlib to graph the data. We create a scatter plot, where class 1 (Iris-Versicolour) is blue triangles and class 2 (Iris-Virginica) is orange circles. We use just two of the features (petel length and petal width) so that it's graphable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 8))\n",
    "xlabel, ylabel = \"petal length (cm)\", \"petal width (cm)\"\n",
    "plt.xlabel(xlabel)\n",
    "plt.ylabel(ylabel)\n",
    "class1 = iris_df[iris_df[\"target\"] == 1]\n",
    "class2 = iris_df[iris_df[\"target\"] == 2]\n",
    "plt.scatter(class1[xlabel], class1[ylabel], marker='^', label=\"Iris-Versicolour\")\n",
    "plt.scatter(class2[xlabel], class2[ylabel], label=\"Iris-Virginica\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Create feature matrix and target array\n",
    "\n",
    "We create a feature matrix `X` that has the values for all the datapoints and the two features that we're using.\n",
    "\n",
    "We create a target array `y` that is the target values (either 1 for Iris-Versicolour or 2 for Iris-Virginica)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = iris_df[[xlabel, ylabel]].values\n",
    "y = iris_df[\"target\"].values\n",
    "print(X)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Split the data into training set and test set\n",
    "\n",
    "We use the `train_test_split` method from scikit-learn to split the dataset into a training set and a test set.\n",
    "\n",
    "We can see the shape (size) of the original and the new feature matrices and target arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "print(\"feature matrix size:\", X.shape)\n",
    "print(\"training feature matrix size:\", X_train.shape)\n",
    "print(\"test feature matrix size:\", X_test.shape)\n",
    "print(\"target array size:\", y.shape)\n",
    "print(\"training target array size:\", y_train.shape)\n",
    "print(\"test target array size:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Build the model\n",
    "\n",
    "Create an instance of the `LogisticRegression` class and use the `fit` method to build the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_model = LogisticRegression().fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make the warning go away, we can specify the solver."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_model = LogisticRegression(solver='lbfgs').fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This determines the coefficients, which we can print out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(iris_model.coef_, iris_model.intercept_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Make predictions\n",
    "\n",
    "We use the `predict` method to make a prediction. First let's make a single prediction of the first datapoint in `X_test` and compare it to the target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"datapoint:\", X_test[0])\n",
    "print(\"target:\", y_test[0])\n",
    "print(\"prediction:\", iris_model.predict([X_test[0]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's make predictions for all the datapoints in `X_test`. We create a DataFrame of the feature values, target and the prediction so we can easily print it out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict = iris_model.predict(X_test)\n",
    "pd.DataFrame({\n",
    "    xlabel: X_test[:, 0],\n",
    "    ylabel: X_test[:, 1],\n",
    "    \"target\": y_test,\n",
    "    \"prediction\": y_predict,\n",
    "    \"correct?\": y_test == y_predict})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Calculate the score\n",
    "\n",
    "We can count how many of the predictions were correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_correct = (y_test == y_predict).sum()\n",
    "num_datapoints = y_test.shape[0]\n",
    "print(f\"accuracy = {num_correct} / {num_datapoints} = {num_correct / num_datapoints}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More simply, use the `score` method to calculate the accuracy score on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(iris_model.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Your Turn!\n",
    "\n",
    "Feel free to approach any exercise first.\n",
    "\n",
    "\n",
    "Here are the general steps to follow when building a model:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1\n",
    "\n",
    "Use all four features (instead of just pedal length and pedal width) in the model for the iris dataset.\n",
    "\n",
    "1. Create an alternative feature matrix `X1` that has all four features.\n",
    "2. Use the `train_test_split` function to create training and test sets.\n",
    "3. Create a `LogisticRegression` model and use the `fit` method with the training set.\n",
    "4. Use the `score` method with the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2\n",
    "\n",
    "Load another model from sklearn and compare the score with linear regression on the iris dataset.\n",
    "\n",
    "**Don't run `train_test_split` again. Use the same train and test sets for all the algorithms.**\n",
    "\n",
    "Here are the docs & import statements for the other classificatoin models:\n",
    "\n",
    "* [Desision tree for classification](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html): `from sklearn.tree import DecisionTreeClassifier`\n",
    "* [Random forest for classification](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html): `from sklearn.ensemble import RandomForestClassifier`\n",
    "* [Neural network for classification](https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPRegressor.html#sklearn.neural_network.MLPClassifier): `from sklearn.neural_network import MLPClassifier`\n",
    "\n",
    "Note that the `fit`, `predict` and `score` methods are the same for all the models.\n",
    "\n",
    "1. Start with the training and test sets.\n",
    "2. Create a `DecisionTreeClassifier` model and use the `fit` method with the training set.\n",
    "3. Use the `score` method with the test set.\n",
    "\n",
    "Which model has the highest accuracy score?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3\n",
    "\n",
    "Try building a model for the boston regression dataset.\n",
    "\n",
    "Here's the import statement: `from sklearn.datasets import load_boston`.\n",
    "\n",
    "Follow the same syntax as with the `load_iris` function.\n",
    "\n",
    "Here's the docs & import statements for the regression models:\n",
    "\n",
    "* [Linear regression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html): `from sklearn.linear_model import LinearRegression`\n",
    "* [Desision tree for regression](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeRegressor.html): `from sklearn.tree import DecisionTreeRegressor`\n",
    "* [Random forest for regression](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html): `from sklearn.ensemble import RandomForestRegressor`\n",
    "* [Neural network for regression](https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPRegressor.html#sklearn.neural_network.MLPRegressor): `from sklearn.neural_network import MLPRegressor`\n",
    "\n",
    "**Make sure to just run `train_test_split` once and not with each model.**\n",
    "\n",
    "1. Load the data with the `load_boston` function.\n",
    "2. Create feature matrix `X` and target array `y`.\n",
    "3. Run `train_test_split` to create training and test sets.\n",
    "4. For each model:\n",
    "    * Create a model and use the `fit` method with the training set.\n",
    "    * Use the `score` method with the test set.\n",
    "\n",
    "Which model has the highest R2 score?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Even more\n",
    "\n",
    "Try building models for other [toy datasets](https://scikit-learn.org/stable/datasets/toy_dataset.html) or some [real world datasets](https://scikit-learn.org/stable/datasets/real_world.html). Or find a fun challenge on [kaggle.com](https://www.kaggle.com/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
